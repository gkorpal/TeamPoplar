{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e91a2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# We start off with the baseline import statements we need to do the basic data manipulation and visualization.\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#We create and set aside a copy of the data for initial exploration\n",
    "housing_train = pd.read_csv('../data/train.csv')\n",
    "housing = housing_train.copy()\n",
    "\n",
    "#MISSING DATA\n",
    "total = housing.isnull().sum().sort_values(ascending=False)\n",
    "percent = (housing.isnull().sum()/housing.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "#CORRELATION CHECK\n",
    "corr_matrix = housing.corr()\n",
    "top_corr = corr_matrix['SalePrice'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b01a5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING SOME COLUMNS\n",
    "drop = ['PoolQC', 'PoolArea','MiscFeature', 'MiscVal', 'Alley', 'Fence', 'FireplaceQu', 'Fireplaces', 'LotFrontage']\n",
    "drop2 = ['Id','GarageArea','1stFlrSF','GarageYrBlt']\n",
    "housing.drop(columns = drop + drop2, inplace = True)\n",
    "housing['Age'] = housing['YrSold'] - housing['YearBuilt']\n",
    "housing['AgeRemodel'] = housing['YrSold'] - housing['YearRemodAdd']\n",
    "housing = housing[housing.AgeRemodel >= 0]\n",
    "housing.drop(columns = ['YearBuilt','YearRemodAdd'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6f1b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FURTHER DATA CLEANING\n",
    "housing_cat = housing.select_dtypes(exclude=[np.number])\n",
    "housing_numeric = housing.select_dtypes(include=[np.number])\n",
    "\n",
    "#Numeric\n",
    "numeric_unbounded = ['LotArea', 'MasVnrArea','BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF',\n",
    "                     'TotalBsmtSF','2ndFlrSF','LowQualFinSF','GrLivArea','WoodDeckSF',\n",
    "                     'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch', 'SalePrice',\n",
    "                     'Age','AgeRemodel']\n",
    "\n",
    "numeric_one_hot = ['MSSubClass','MoSold']\n",
    "\n",
    "numeric_ordinal = [x for x in housing_numeric.columns \n",
    "                   if (x not in numeric_unbounded and x not in numeric_one_hot)]\n",
    "\n",
    "housing_numeric_unbounded = housing_numeric[numeric_unbounded]\n",
    "housing_numeric_one_hot = housing_numeric[numeric_one_hot]\n",
    "housing_numeric_ordinal = housing_numeric[numeric_ordinal]\n",
    "\n",
    "housing_numeric_one_hot['MSSubClass'] = housing_numeric_one_hot['MSSubClass'].astype('str')\n",
    "housing_numeric_one_hot['MoSold'] = housing_numeric_one_hot['MoSold'].replace({i:calendar.month_name[i][:3] for i in range(1,13)})\n",
    "housing_numeric_one_hot = pd.get_dummies(housing_numeric_one_hot)\n",
    "\n",
    "#Categorical\n",
    "cat_ordinal = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "               'BsmtFinType1', 'HeatingQC', 'KitchenQual','Functional','GarageFinish',\n",
    "               'GarageQual', 'GarageCond']\n",
    "\n",
    "housing_cat_ordinal = housing_cat[cat_ordinal]\n",
    "housing_cat_ordinal.fillna('None', inplace = True)\n",
    "housing_cat_one_hot = housing_cat.drop(columns = cat_ordinal)\n",
    "housing_cat_one_hot = pd.get_dummies(housing_cat_one_hot)\n",
    "\n",
    "def mapper(cat):\n",
    "    if cat in ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond',\n",
    "               'HeatingQC', 'KitchenQual']:\n",
    "        mapper = {'None':0, 'Po':1, 'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "    elif cat == 'BsmtExposure':\n",
    "            mapper = {'None':0,'No':1, 'Mn':2, 'Av':3,'Gd':4}\n",
    "    elif cat == 'BsmtFinType1':\n",
    "        mapper = {'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6}\n",
    "    elif cat == 'Functional':\n",
    "        mapper = {'Sal':0,'Sev':1,'Maj2':2,'Maj1':3,'Mod':4,'Min2':5, 'Min1':6,'Typ':7}\n",
    "    else:\n",
    "        mapper = {'None':0,'Unf':1,'RFn':2,'Fin':3}\n",
    "        \n",
    "    return mapper\n",
    "\n",
    "for cat in cat_ordinal:\n",
    "    housing_cat_ordinal[cat].replace(mapper(cat), inplace = True)\n",
    "\n",
    "#Combining numeric and categorical\n",
    "housing_ordinal = pd.concat([housing_numeric_ordinal,housing_cat_ordinal], axis = 'columns')\n",
    "housing_one_hot = pd.concat([housing_numeric_one_hot, housing_cat_one_hot], axis = 'columns')\n",
    "housing_clean = pd.concat([housing_one_hot, housing_ordinal, housing_numeric_unbounded], \n",
    "                          axis = 'columns')\n",
    "\n",
    "#MORE CORRELATION\n",
    "ordinal_prices = pd.concat([housing_ordinal, housing['SalePrice']], axis = 'columns')\n",
    "ordinal_corr_matrix = ordinal_prices.corr()\n",
    "top_corr_ordinal = ordinal_corr_matrix['SalePrice'].sort_values(ascending = False)\n",
    "\n",
    "one_hot_prices = pd.concat([housing_one_hot, housing['SalePrice']], axis = 'columns')\n",
    "one_hot_corr_matrix = one_hot_prices.corr()\n",
    "top_corr_one_hot = one_hot_corr_matrix['SalePrice'].filter(like = 'Neighborhood').sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c5d3650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVAL OF THE REMAINING NaN\n",
    "housing_clean.isnull().sum().sort_values(ascending=False)\n",
    "df = housing_clean.copy()\n",
    "problem_col = df.isin([np.nan, np.inf, -np.inf]).sum(axis=0)[df.isin([np.nan, np.inf, -np.inf]).sum(axis=0) != 0] \n",
    "index_to_drop = df[problem_col.index[0]][df[problem_col.index[0]].isin([np.nan, np.inf, -np.inf])].index\n",
    "df.drop(index = index_to_drop, inplace = True)\n",
    "# df.isnull().sum().sort_values(ascending=False)\n",
    "df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f08a6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST FOR FEATURE IMPORTANCE\n",
    "X_train = df.drop(columns = ['SalePrice'])\n",
    "y_train = df['SalePrice']\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, max_depth=4)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "forest.feature_importances_\n",
    "score_df = pd.DataFrame({'feature':X_train.columns,\n",
    "                            'importance_score': forest.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe8461b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will look at feature importances and their correlation with the 'SalePrice'\n",
    "score_df.sort_values('feature', inplace=True)\n",
    "top_corr = df.corr()['SalePrice'].abs().drop(index = ['SalePrice']) #I suppose we want to look at the absolute value\n",
    "                                                                    #of the correlation. Is that right?\n",
    "top_corr.sort_index(inplace=True) \n",
    "#now rows of score_df and top_corr match and we can add the values of correlation\n",
    "score_df['correlation'] = top_corr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "17ede219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_score</th>\n",
       "      <th>correlation</th>\n",
       "      <th>importance_score_rank</th>\n",
       "      <th>correlation_rank</th>\n",
       "      <th>overall_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExterQual</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.68</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FullBath</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AgeRemodel</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.51</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foundation_PConc</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>28.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HeatingQC</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.43</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>21.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Neighborhood_NridgHt</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>113.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MSSubClass_60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>43.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BsmtExposure</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.37</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MasVnrType_None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>181</td>\n",
       "      <td>20</td>\n",
       "      <td>100.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  importance_score  correlation  \\\n",
       "0            OverallQual              0.02         0.79   \n",
       "1              GrLivArea              0.04         0.72   \n",
       "2              ExterQual              0.01         0.68   \n",
       "3            KitchenQual              0.01         0.66   \n",
       "4             GarageCars              0.02         0.64   \n",
       "5            TotalBsmtSF              0.03         0.62   \n",
       "6               BsmtQual              0.01         0.58   \n",
       "7               FullBath              0.02         0.56   \n",
       "8           GarageFinish              0.01         0.55   \n",
       "9           TotRmsAbvGrd              0.02         0.54   \n",
       "10                   Age              0.03         0.52   \n",
       "11            AgeRemodel              0.02         0.51   \n",
       "12      Foundation_PConc              0.00         0.50   \n",
       "13            MasVnrArea              0.02         0.48   \n",
       "14             HeatingQC              0.01         0.43   \n",
       "15  Neighborhood_NridgHt              0.00         0.40   \n",
       "16            BsmtFinSF1              0.02         0.39   \n",
       "17         MSSubClass_60              0.00         0.38   \n",
       "18          BsmtExposure              0.01         0.37   \n",
       "19       MasVnrType_None              0.00         0.37   \n",
       "\n",
       "    importance_score_rank  correlation_rank  overall_rank  \n",
       "0                       5                 1          3.00  \n",
       "1                       1                 2          1.50  \n",
       "2                      21                 3         12.00  \n",
       "3                      18                 4         11.00  \n",
       "4                      15                 5         10.00  \n",
       "5                       4                 6          5.00  \n",
       "6                      16                 7         11.50  \n",
       "7                       9                 8          8.50  \n",
       "8                      19                 9         14.00  \n",
       "9                      10                10         10.00  \n",
       "10                      3                11          7.00  \n",
       "11                     13                12         12.50  \n",
       "12                     44                13         28.50  \n",
       "13                     14                14         14.00  \n",
       "14                     28                15         21.50  \n",
       "15                    210                16        113.00  \n",
       "16                      6                17         11.50  \n",
       "17                     69                18         43.50  \n",
       "18                     37                19         28.00  \n",
       "19                    181                20        100.50  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(ascending=False, by = ['importance_score'], inplace = True)\n",
    "score_df['importance_score_rank'] = [k for k in range(1,1+len(score_df.index))]\n",
    "score_df.sort_values(ascending=False, by = ['correlation'], inplace = True)\n",
    "score_df['correlation_rank'] = [k for k in range(1,1+len(score_df.index))]\n",
    "score_df['overall_rank'] = (score_df['importance_score_rank'] + score_df['correlation_rank'])/2 \n",
    "# score_df.sort_values(ascending=True, by = ['overall_rank'], inplace = True)\n",
    "score_df.sort_values(ascending=True, by = ['correlation_rank'], inplace = True)\n",
    "score_df.reset_index(drop = True, inplace = True)\n",
    "score_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e60ce",
   "metadata": {},
   "source": [
    "Correlation measures only linear dependence between variables and it does not detect non-linear dependence (in particular cor(X,Y) can be 0 for random variables X and Y=X^2, which are of course completely dependent). So, if a given feature has high feature_importance score, but low correlation it means that 'SalePrice' depend on it in a non-linear manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45386661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 7))\n",
    "# plt.scatter(score_df['importance_score_rank'][:20], score_df['correlation_rank'][:20], c =\"blue\",\n",
    "#             linewidths = 1)\n",
    "# plt.title('importance_rank vs correlation_rank')\n",
    "# plt.xticks(np.arange(0, 40, step=1))\n",
    "# plt.yticks(np.arange(0, 40, step=1))\n",
    "# plt.xlabel(\"importance_score_rank\")\n",
    "# plt.ylabel(\"correlation_rank\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dcb6f1",
   "metadata": {},
   "source": [
    "FITTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "958b004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "09090aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_hat, y):\n",
    "#     print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - y)))\n",
    "#     print(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - y) ** 2))\n",
    "#     print( f'Normalized sum of squares error: {round(100*np.mean((y_hat - y) ** 2) / (np.mean(y ** 2)), 2)}%' )\n",
    "#     print(\"R2-score: %.2f\" % r2_score(y_hat, y) )\n",
    "    return [round(np.mean(np.absolute(y_hat - y)), 2), round(np.mean((y_hat - y) ** 2),2), \n",
    "            round(np.mean((y_hat - y) ** 2) / (np.mean(y ** 2)),2), \n",
    "            round(r2_score(y_hat, y),2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4934eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Simple linear regression\n",
      "=====================\n",
      "Coefficients in simple linear regression:  [113.59]\n",
      "Intercept in simple linear regression:  10421.43\n",
      "Variance score: 0.41\n",
      "=====================\n",
      "Multi-linear regression with all features\n",
      "=====================\n",
      "20 largest coefficients in multilinear regression: [82498.43, 68506.77, 49419.57, 46486.33, 43926.93, 38319.1, 35919.26, 29830.22, 29563.87, 25234.09, 24780.46, 23846.01, 23756.84, 23619.17, 23121.44, 22544.47, 21741.07, 20590.38, 19544.18, 19294.77]\n",
      "Intercept in multilinear regression: -858608.98\n",
      "Variance score: 0.63\n",
      "=====================\n",
      "Multi-linear regression using 3 features most correlated with the SalePrice\n",
      "=====================\n",
      "Coefficients in multilinear regression:[63.67, 22527.06, 31977.65]\n",
      "Intercept in multilinear regression:  -160386.0\n"
     ]
    }
   ],
   "source": [
    "#Train-test split\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "#MODEL 1: Simple linear regression\n",
    "print('=====================')\n",
    "print('Simple linear regression')\n",
    "print('=====================')\n",
    "\n",
    "#a) Data preparation\n",
    "X_train = train['GrLivArea'].values.reshape(-1,1)\n",
    "y_train = train['SalePrice']\n",
    "X_test = test['GrLivArea'].values.reshape(-1,1)\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "print ('Coefficients in simple linear regression: ', [round(num,2) for num in regr.coef_])\n",
    "print ('Intercept in simple linear regression: ', round(regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph\n",
    "# plt.scatter(train.GrLivArea, train.SalePrice,  color='blue')\n",
    "# plt.plot(train.GrLivArea, regr.coef_*train.GrLivArea + regr.intercept_, '-r')\n",
    "# plt.title('GrLivArea vs SalePrice')\n",
    "# plt.xlabel(\"GrLivArea\")\n",
    "# plt.ylabel(\"SalePrice\")\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = regr.predict(X_test)\n",
    "metrics['SLR'] = eval(y_test_hat, y_test )\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "\n",
    "#MODEL 2: Multi-linear regression with all features\n",
    "print('=====================')\n",
    "print('Multi-linear regression with all features')\n",
    "print('=====================')\n",
    "#a) Data preparation\n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "ml_regr = linear_model.LinearRegression()\n",
    "ml_regr.fit(X_train, y_train)\n",
    "print (f'20 largest coefficients in multilinear regression: {[round(num, 2) for num in sorted(ml_regr.coef_, reverse=True)[:20]]}')\n",
    "print ('Intercept in multilinear regression: %.2f' % round(ml_regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph - not clear how to do it in this case.\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = ml_regr.predict(X_test)\n",
    "metrics['MLR'] = eval(y_test_hat, y_test)\n",
    "print('Variance score: %.2f' % ml_regr.score(X_test, y_test))\n",
    "\n",
    "#MODEL 3: Multi-linear regression using 3 features most correlated with the SalePrice\n",
    "print('=====================')\n",
    "print('Multi-linear regression using 3 features most correlated with the SalePrice')\n",
    "print('=====================')\n",
    "#a) Data preparation\n",
    "X_train = train[['GrLivArea','OverallQual', 'ExterQual']]\n",
    "y_train = train['SalePrice']\n",
    "X_test = test[['GrLivArea','OverallQual', 'ExterQual']]\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "ml3_regr = linear_model.LinearRegression()\n",
    "ml3_regr.fit(X_train, y_train)\n",
    "print (f'Coefficients in multilinear regression:{[round(num, 2) for num in ml3_regr.coef_]}')\n",
    "print ('Intercept in multilinear regression: ', round(ml3_regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph - not clear how to do it in this case.\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = ml3_regr.predict(X_test)\n",
    "metrics['MLR3'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b5f4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 4: k nearest neighbors regression\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1, 10):\n",
    "    y_test_hat = KNeighborsRegressor(x).fit(X_train,y_train).predict(X_test)\n",
    "#     print('=====================')\n",
    "#     print(f'KNN regression with k = {x}')\n",
    "#     print('=====================')\n",
    "    metrics[f'KNN_{x}']= eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4282caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 5: SVM regression\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1,5):\n",
    "    y_test_hat = LinearSVR(C=1, epsilon=25000*x, max_iter=100000).fit(X_train,y_train).predict(X_test)\n",
    "#     print('=====================')\n",
    "#     print(f'Support vector regression with epsilon = {25000*x}')\n",
    "#     print('=====================')\n",
    "    metrics[f'SVM_epsilon={25000*x}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b0a6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 6, 7: Decision tree and Random forest\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1,10):\n",
    "    y_test_hat = DecisionTreeRegressor(max_depth = x).fit(X_train,y_train).predict(X_test)\n",
    "    metrics[f'Decision_tree_max_depth={x}'] = eval(y_test_hat, y_test)\n",
    "    \n",
    "    y_test_hat = RandomForestRegressor(max_depth = x).fit(X_train,y_train).predict(X_test)\n",
    "    metrics[f'Random_forest_max_depth={x}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68e1fc",
   "metadata": {},
   "source": [
    "Below we will study several regularized regression model. Their common feature is that they all penalize large regression coefficients. In case of Ridge regression it is achieved by adding $\\alpha\\|\\beta\\|^2_{\\ell^2}$ to the MSE. In LASSO regression one adds $\\alpha\\|\\beta\\|_{\\ell^1}$ instead. Finally, in the Elastic Net approach we add a convex combination:\n",
    "$\\alpha\\Big[r\\|\\beta\\|^2_{\\ell^2}+(1-r)\\|\\beta\\|_{\\ell^1}\\Big]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e4f1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 8,9 and 10: Regularized regression models\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_rescaled = scaler.transform(X_train)\n",
    "X_test_rescaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "023b7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d) Prediction and evaluation\n",
    "\n",
    "for x in range(1,10):\n",
    "\n",
    "#With rescaling\n",
    "\n",
    "    y_test_hat = Ridge(alpha= x/10).fit(X_train_rescaled, y_train).predict(X_test_rescaled)\n",
    "    metrics[f'Ridge rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "    \n",
    "    y_test_hat = Lasso(alpha= x/10).fit(X_train_rescaled, y_train).predict(X_test_rescaled)\n",
    "    metrics[f'Lasso rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "\n",
    "#Without rescaling:\n",
    "    \n",
    "    y_test_hat = Ridge(alpha= x/10).fit(X_train, y_train).predict(X_test)\n",
    "    metrics[f'Ridge not rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "\n",
    "    y_test_hat = Lasso(alpha= x/10).fit(X_train, y_train).predict(X_test)\n",
    "    metrics[f'Lasso not rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "\n",
    "    \n",
    "    for r in range(1,10):\n",
    "        \n",
    "            y_test_hat = ElasticNet(alpha= x/10, l1_ratio = r/10).fit(X_train, y_train).predict(X_test)\n",
    "            metrics[f'ElasticNet not rescaled with alpha={x/10} and r={r/10}'] = eval(y_test_hat, y_test)\n",
    "            \n",
    "            y_test_hat = ElasticNet(alpha= x/10, l1_ratio = r/10).fit(X_train_rescaled, y_train).predict(X_test_rescaled)\n",
    "            metrics[f'ElasticNet rescaled with alpha={x/10} and r={r/10}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models 11, 12 and 13: Boosted models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "665c1a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>relative MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.1 and r=0.8</th>\n",
       "      <td>18591.56</td>\n",
       "      <td>834586610.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNeT rescaled with alpha=0.2 and r=0.9</th>\n",
       "      <td>18591.12</td>\n",
       "      <td>834550417.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.2 and r=0.9</th>\n",
       "      <td>18591.12</td>\n",
       "      <td>834550417.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNeT rescaled with alpha=0.1 and r=0.8</th>\n",
       "      <td>18591.56</td>\n",
       "      <td>834586610.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso not rescaled with alpha=0.9</th>\n",
       "      <td>18952.31</td>\n",
       "      <td>867999790.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=2</th>\n",
       "      <td>36972.16</td>\n",
       "      <td>3146433453.59</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_9</th>\n",
       "      <td>32467.51</td>\n",
       "      <td>2953077651.94</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLR</th>\n",
       "      <td>38732.03</td>\n",
       "      <td>3107016842.50</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=1</th>\n",
       "      <td>45256.99</td>\n",
       "      <td>4012498211.59</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest_max_depth=1</th>\n",
       "      <td>40479.92</td>\n",
       "      <td>3603131503.55</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  MAE           MSE  \\\n",
       "ElasticNet rescaled with alpha=0.1 and r=0.8 18591.56  834586610.99   \n",
       "ElasticNeT rescaled with alpha=0.2 and r=0.9 18591.12  834550417.73   \n",
       "ElasticNet rescaled with alpha=0.2 and r=0.9 18591.12  834550417.73   \n",
       "ElasticNeT rescaled with alpha=0.1 and r=0.8 18591.56  834586610.99   \n",
       "Lasso not rescaled with alpha=0.9            18952.31  867999790.84   \n",
       "...                                               ...           ...   \n",
       "Decision_tree_max_depth=2                    36972.16 3146433453.59   \n",
       "KNN_9                                        32467.51 2953077651.94   \n",
       "SLR                                          38732.03 3107016842.50   \n",
       "Decision_tree_max_depth=1                    45256.99 4012498211.59   \n",
       "Random_forest_max_depth=1                    40479.92 3603131503.55   \n",
       "\n",
       "                                              relative MSE    R2  \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.8          0.02  0.87  \n",
       "ElasticNeT rescaled with alpha=0.2 and r=0.9          0.02  0.87  \n",
       "ElasticNet rescaled with alpha=0.2 and r=0.9          0.02  0.87  \n",
       "ElasticNeT rescaled with alpha=0.1 and r=0.8          0.02  0.87  \n",
       "Lasso not rescaled with alpha=0.9                     0.02  0.86  \n",
       "...                                                    ...   ...  \n",
       "Decision_tree_max_depth=2                             0.08  0.07  \n",
       "KNN_9                                                 0.07  0.03  \n",
       "SLR                                                   0.08  0.03  \n",
       "Decision_tree_max_depth=1                             0.10 -0.32  \n",
       "Random_forest_max_depth=1                             0.09 -0.43  \n",
       "\n",
       "[313 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "df = pd.DataFrame.from_dict(metrics, orient='index', dtype=float, columns= ['MAE', 'MSE','relative MSE', 'R2'])\n",
    "sorted_df = df.sort_values(by = ['R2'], ascending = False)\n",
    "sorted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
